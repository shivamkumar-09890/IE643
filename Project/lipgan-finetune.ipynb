{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10014786,"sourceType":"datasetVersion","datasetId":6165821}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q ffmpeg-python librosa opencv-python-headless tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T04:01:06.396579Z","iopub.execute_input":"2024-11-26T04:01:06.396852Z","iopub.status.idle":"2024-11-26T04:01:15.942652Z","shell.execute_reply.started":"2024-11-26T04:01:06.396826Z","shell.execute_reply":"2024-11-26T04:01:15.941704Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import cv2\nimport os\nfrom tqdm import tqdm\n\n# Paths\nvideo_path = \"/kaggle/input/dataset23/UPSC_Mains.mp4\"\nframes_dir = \"/kaggle/working/data/frames\"\n\nos.makedirs(frames_dir, exist_ok=True)\n\n# Load video\ncap = cv2.VideoCapture(video_path)\nfps = int(cap.get(cv2.CAP_PROP_FPS))  # Get frame rate\n\n# Extract frames\nframe_count = 0\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Resize the frame to 96x96 (you may need face cropping here)\n    frame_resized = cv2.resize(frame, (96, 96))\n    \n    # Save the frame\n    frame_path = os.path.join(frames_dir, f\"frame_{frame_count:05d}.jpg\")\n    cv2.imwrite(frame_path, frame_resized)\n    frame_count += 1\n\ncap.release()\nprint(f\"Extracted {frame_count} frames at {fps} FPS\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T04:02:31.596202Z","iopub.execute_input":"2024-11-26T04:02:31.596965Z","iopub.status.idle":"2024-11-26T04:04:27.867291Z","shell.execute_reply.started":"2024-11-26T04:02:31.596929Z","shell.execute_reply":"2024-11-26T04:04:27.866353Z"}},"outputs":[{"name":"stdout","text":"Extracted 221180 frames at 25 FPS\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import ffmpeg\n\naudio_path = \"/kaggle/working/data/audio.wav\"\nos.makedirs(\"data\", exist_ok=True)\n\n# Extract audio from video\nffmpeg.input(video_path).output(audio_path, ac=1, ar=16000).run(overwrite_output=True)\nprint(f\"Extracted audio saved to {audio_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T04:04:27.868780Z","iopub.execute_input":"2024-11-26T04:04:27.869344Z","iopub.status.idle":"2024-11-26T04:04:41.544486Z","shell.execute_reply.started":"2024-11-26T04:04:27.869315Z","shell.execute_reply":"2024-11-26T04:04:41.543645Z"}},"outputs":[{"name":"stderr","text":"ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from '/kaggle/input/dataset23/UPSC_Mains.mp4':\n  Metadata:\n    major_brand     : mp42\n    minor_version   : 0\n    compatible_brands: isommp42\n    creation_time   : 2022-01-10T21:27:33.000000Z\n  Duration: 02:27:27.22, start: 0.000000, bitrate: 212 kb/s\n  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 80 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n    Metadata:\n      creation_time   : 2022-01-10T21:27:33.000000Z\n      handler_name    : ISO Media file produced by Google Inc. Created on: 01/10/2022.\n      vendor_id       : [0][0][0][0]\n  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n    Metadata:\n      creation_time   : 2022-01-10T21:27:33.000000Z\n      handler_name    : ISO Media file produced by Google Inc. Created on: 01/10/2022.\n      vendor_id       : [0][0][0][0]\nStream mapping:\n  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\nPress [q] to stop, [?] for help\nOutput #0, wav, to 'data/audio.wav':\n  Metadata:\n    major_brand     : mp42\n    minor_version   : 0\n    compatible_brands: isommp42\n    ISFT            : Lavf58.76.100\n  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n    Metadata:\n      creation_time   : 2022-01-10T21:27:33.000000Z\n      handler_name    : ISO Media file produced by Google Inc. Created on: 01/10/2022.\n      vendor_id       : [0][0][0][0]\n      encoder         : Lavc58.134.100 pcm_s16le\nsize=  265984kB time=02:21:58.77 bitrate= 255.8kbits/s speed= 681x    \r","output_type":"stream"},{"name":"stdout","text":"Extracted audio saved to data/audio.wav\n","output_type":"stream"},{"name":"stderr","text":"size=  276476kB time=02:27:27.21 bitrate= 256.0kbits/s speed= 682x    \nvideo:0kB audio:276476kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000028%\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import librosa\nimport numpy as np\nimport os\n\ndef audio_to_mel(audio_path, output_dir, hop_length=160, n_fft=400, n_mels=80, chunk_size=128):\n    # Load audio\n    y, sr = librosa.load(audio_path, sr=16000)\n    \n    # Compute mel spectrogram\n    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n    mel_db = librosa.power_to_db(mel, ref=np.max)\n    \n    # Ensure output directory exists\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Split mel spectrogram into chunks\n    num_frames = mel_db.shape[1]\n    for i in range(0, num_frames, chunk_size):\n        mel_chunk = mel_db[:, i:i + chunk_size]\n        np.save(os.path.join(output_dir, f\"mel_{i // chunk_size:05d}.npy\"), mel_chunk)\n    \n    print(f\"Generated {num_frames // chunk_size} mel-spectrogram chunks\")\n\n# Example usage\naudio_path = '/kaggle/working/data/audio.wav'\nmel_dir = '/kaggle/working/data/mels'\naudio_to_mel(audio_path, mel_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T04:16:27.078009Z","iopub.execute_input":"2024-11-26T04:16:27.078717Z","iopub.status.idle":"2024-11-26T04:16:35.228135Z","shell.execute_reply.started":"2024-11-26T04:16:27.078678Z","shell.execute_reply":"2024-11-26T04:16:35.227200Z"}},"outputs":[{"name":"stdout","text":"Generated 6911 mel-spectrogram chunks\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T04:26:11.666514Z","iopub.execute_input":"2024-11-26T04:26:11.667382Z","iopub.status.idle":"2024-11-26T04:26:11.672896Z","shell.execute_reply.started":"2024-11-26T04:26:11.667347Z","shell.execute_reply":"2024-11-26T04:26:11.671956Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!pip install -q torch torchvision torchaudio\n!pip install -q opencv-python-headless matplotlib tqdm\n!git clone https://github.com/Rudrabha/LipGAN.git\n%cd LipGAN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T04:26:14.158226Z","iopub.execute_input":"2024-11-26T04:26:14.159384Z","iopub.status.idle":"2024-11-26T04:26:31.693849Z","shell.execute_reply.started":"2024-11-26T04:26:14.159348Z","shell.execute_reply":"2024-11-26T04:26:31.692748Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'LipGAN' already exists and is not an empty directory.\n/kaggle/working/LipGAN\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!wget https://www.iiitvidya.com/pretrained/LipGAN.pth -P checkpoints/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T04:17:59.171068Z","iopub.execute_input":"2024-11-26T04:17:59.171804Z","iopub.status.idle":"2024-11-26T04:18:00.309264Z","shell.execute_reply.started":"2024-11-26T04:17:59.171771Z","shell.execute_reply":"2024-11-26T04:18:00.308178Z"}},"outputs":[{"name":"stdout","text":"--2024-11-26 04:18:00--  https://www.iiitvidya.com/pretrained/LipGAN.pth\nResolving www.iiitvidya.com (www.iiitvidya.com)... failed: Name or service not known.\nwget: unable to resolve host address 'www.iiitvidya.com'\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"load_checkpoint = True\ncheckpoint_path = \"checkpoints/LipGAN.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T04:18:00.310690Z","iopub.execute_input":"2024-11-26T04:18:00.311014Z","iopub.status.idle":"2024-11-26T04:18:00.315407Z","shell.execute_reply.started":"2024-11-26T04:18:00.310982Z","shell.execute_reply":"2024-11-26T04:18:00.314543Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import DataLoader\nfrom model import LipGAN\nfrom datasets.lrs2 import LRS2Dataset\nfrom hparams import hparams as hp\nfrom utils import load_checkpoint, save_checkpoint\n\ndef fine_tune():\n    # Paths\n    data_root = '/kaggle/working/data'  # Path to your fine-tuning dataset\n    checkpoint_dir = '/kaggle/working/checkpoints'  # Directory to save checkpoints\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    \n    # Dataset paths for frames and mel spectrograms\n    audio_path = os.path.join(data_root, 'audio.wav')\n    frames_dir = os.path.join(data_root, 'frames')\n    mels_dir = os.path.join(data_root, 'mels')\n    \n    # Dataset\n    fine_tune_dataset = LRS2Dataset(audio_path, frames_dir, mels_dir, split='train', augment=True)\n    fine_tune_loader = DataLoader(fine_tune_dataset, batch_size=hp.batch_size, shuffle=True, num_workers=4)\n    \n    # Model\n    model = LipGAN().cuda()  # Ensure GPU is enabled\n    optimizer = torch.optim.Adam(model.parameters(), lr=hp.lr)\n    \n    # Load Pretrained Weights\n    start_epoch = 0\n    if hp.load_checkpoint:\n        start_epoch = load_checkpoint(hp.checkpoint_path, model, optimizer)\n        print(f\"Loaded pretrained weights from {hp.checkpoint_path}\")\n    \n    # Fine-Tuning Loop\n    for epoch in range(start_epoch, hp.epochs):\n        model.train()\n        for step, (video_frames, audio_mels, labels) in enumerate(fine_tune_loader):\n            video_frames = video_frames.cuda()\n            audio_mels = audio_mels.cuda()\n            labels = labels.cuda()\n            \n            # Forward pass\n            preds = model(video_frames, audio_mels)\n            loss = model.loss_function(preds, labels)\n            \n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            # Logging\n            if step % hp.log_interval == 0:\n                print(f\"Epoch [{epoch}/{hp.epochs}], Step [{step}/{len(fine_tune_loader)}], Loss: {loss.item():.4f}\")\n        \n        # Save Checkpoint\n        save_checkpoint(os.path.join(checkpoint_dir, f\"fine_tuned_epoch_{epoch}.pth\"), model, optimizer, epoch)\n        print(f\"Checkpoint saved at epoch {epoch}.\")\n\nif __name__ == \"__main__\":\n    fine_tune()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T04:23:01.571415Z","iopub.execute_input":"2024-11-26T04:23:01.571788Z","iopub.status.idle":"2024-11-26T04:23:04.672861Z","shell.execute_reply.started":"2024-11-26T04:23:01.571760Z","shell.execute_reply":"2024-11-26T04:23:04.671571Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LipGAN\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlrs2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LRS2Dataset\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhparams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hparams \u001b[38;5;28;01mas\u001b[39;00m hp\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"],"ename":"ModuleNotFoundError","evalue":"No module named 'model'","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"!zip -r fine_tuned_model.zip checkpoints/\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}