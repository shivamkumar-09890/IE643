{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYLdoP3BnjSA"
   },
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zN_-5EgknjSF"
   },
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_g_s_rlnjSG"
   },
   "source": [
    "<h1>Problem Explanation</h1>\n",
    "\n",
    "<p>The problem involves checking whether a given dataset\n",
    "<code>D = {(x_i, y_i)}_{i=1}^{n}</code>, where <code>x_i &in; &Ropf;^d</code> and <code>y_i &in; {+1, -1}</code>, is linearly separable.</p>\n",
    "\n",
    "<p>A dataset is linearly separable if there exists a non-zero vector <code>w^* &in; &Ropf;^d</code>, some bias <code>b &in; &Ropf;</code>, and a margin <code>&gamma; &gt; 0</code> such that for every <code>i &in; {1, 2, ..., n}</code>:</p>\n",
    "\n",
    "<pre>\n",
    "y_i (〈 w^*, x_i 〉 - b) ≥ γ\n",
    "</pre>\n",
    "\n",
    "<h2>Key Components of the Problem</h2>\n",
    "\n",
    "<h3>Goal</h3>\n",
    "\n",
    "<p>Find if a linear separator <code>w^*, b</code> exists such that all data points are separated by a margin <code>&gamma;</code>.</p>\n",
    "\n",
    "<h3>Optimization Problem</h3>\n",
    "\n",
    "<p>We aim to formulate an optimization problem of the form:</p>\n",
    "\n",
    "<pre>\n",
    "min_{z} f(z) subject to A z ≤ q\n",
    "</pre>\n",
    "\n",
    "<p>where <code>z</code> represents the decision variables, and <code>A</code> and <code>q</code> encode the constraints that capture whether the data is linearly separable.</p>\n",
    "\n",
    "<h3>Steps to Formulate the Optimization Problem:</h3>\n",
    "\n",
    "<h4>Decision Variables <code>z</code>:</h4>\n",
    "\n",
    "<p>The decision variables will include the weight vector <code>w</code>, the bias <code>b</code>, and the margin <code>&gamma;</code>. Let:</p>\n",
    "\n",
    "<pre>\n",
    "z = (w, b, γ) ∈ &Ropf;^{d+2}\n",
    "</pre>\n",
    "\n",
    "<p>where <code>w &in; &Ropf;^d</code>, <code>b &in; &Ropf;</code>, and <code>&gamma; &gt; 0</code>.</p>\n",
    "\n",
    "<h4>Constraints:</h4>\n",
    "\n",
    "<p>The main condition for linear separability is:</p>\n",
    "\n",
    "<pre>\n",
    "y_i (〈 w, x_i 〉 - b) ≥ γ\n",
    "</pre>\n",
    "\n",
    "<p>This can be rewritten as:</p>\n",
    "\n",
    "<pre>\n",
    "y_i (〈 w, x_i 〉 - b) - γ ≥ 0\n",
    "</pre>\n",
    "\n",
    "<p>For each data point <code>i &in; {1, 2, ..., n}</code>, we have the constraint:</p>\n",
    "\n",
    "<pre>\n",
    "y_i (〈 w, x_i 〉 - b) - γ ≥ 0\n",
    "</pre>\n",
    "\n",
    "<p>This can be compactly written in matrix form as:</p>\n",
    "\n",
    "<pre>\n",
    "A z ≤ q\n",
    "</pre>\n",
    "\n",
    "<p>where <code>A &in; &Ropf;^{n × (d+2)}</code> and <code>q &in; &Ropf;^n</code>. The structure of <code>A</code> and <code>q</code> is as follows:</p>\n",
    "\n",
    "<h4>Matrix <code>A</code>:</h4>\n",
    "\n",
    "<pre>\n",
    "A =\n",
    "| -y_1 x_1^⊤ & y_1 & -1 |\n",
    "| -y_2 x_2^⊤ & y_2 & -1 |\n",
    "|  ...     ...      ...  |\n",
    "| -y_n x_n^⊤ & y_n & -1 |\n",
    "</pre>\n",
    "\n",
    "<h4>Vector <code>q</code>:</h4>\n",
    "\n",
    "<pre>\n",
    "q =\n",
    "| 0 |\n",
    "| 0 |\n",
    "| . |\n",
    "| . |\n",
    "| 0 |\n",
    "</pre>\n",
    "\n",
    "<p>These constraints encode the linear separability condition for all data points.</p>\n",
    "\n",
    "<h4>Objective Function <code>f(z)</code>:</h4>\n",
    "\n",
    "<p>Since we are not optimizing anything specific (we just want to check for the existence of a linear separator), a suitable choice of the objective function can be a simple regularization term to enforce non-triviality of the solution, such as the norm of <code>w</code>:</p>\n",
    "\n",
    "<pre>\n",
    "f(z) = ||w||^2\n",
    "</pre>\n",
    "\n",
    "<p>This ensures we are not simply looking for the trivial solution <code>w = 0</code>. It can also be set to any constant since we are not interested in the actual value but only in feasibility.</p>\n",
    "\n",
    "<h2>Final Optimization Problem:</h2>\n",
    "\n",
    "<p>Thus, the final optimization problem can be written as:</p>\n",
    "\n",
    "<pre>\n",
    "min_{z} ||w||^2 subject to A z ≤ q\n",
    "</pre>\n",
    "\n",
    "<p>where:</p>\n",
    "<ul>\n",
    "  <li><code>z = (w, b, γ) &in; &Ropf;^{d+2}</code>,</li>\n",
    "  <li><code>A &in; &Ropf;^{n × (d+2)}</code> is the matrix encoding the constraints, and</li>\n",
    "  <li><code>q &in; &Ropf;^n</code> is a zero vector.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Structure, Shape, and Content of Matrices:</h3>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Decision Variables <code>z</code></strong>: <code>z &in; &Ropf;^{d+2}</code>, where <code>w &in; &Ropf;^d</code>, <code>b &in; &Ropf;</code>, and <code>&gamma; &in; &Ropf;^1</code>.</li>\n",
    "  <li><strong>Matrix <code>A</code></strong>: <code>A &in; &Ropf;^{n × (d+2)}</code>, with each row of the form <code>(-y_i x_i^⊤, y_i, -1)</code>.</li>\n",
    "  <li><strong>Vector <code>q</code></strong>: <code>q &in; &Ropf;^n</code>, all entries are zero.</li>\n",
    "</ul>\n",
    "\n",
    "<h2>Conclusion:</h2>\n",
    "\n",
    "<p>This optimization problem allows us to check whether a dataset is linearly separable. If a feasible solution <code>z = (w, b, γ)</code> exists such that <code>γ &gt; 0</code>, the dataset is linearly separable. If no such solution exists, the dataset is not linearly separable. The structure of the optimization problem ensures that we respect the condition <code>y_i (〈 w, x_i 〉 - b) ≥ γ</code> for all data points.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRZQhYWonjSJ"
   },
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIcYp5IKnjSK"
   },
   "source": [
    "<p>To implement and solve the optimization problem, we will use <strong>CVXPY</strong>, a popular open-source Python library for convex optimization. This will allow us to check if the dataset is linearly separable using the optimization formulation we derived earlier.</p>\n",
    "\n",
    "<h3>Steps to Implement:</h3>\n",
    "<ol>\n",
    "  <li>Install the <strong>cvxpy</strong> package</li>\n",
    "  <li>Define the decision variables <code>z = (w, b, γ)</code>.</li>\n",
    "  <li>Define the matrix <code>A</code> and vector <code>q</code> as per the optimization formulation.</li>\n",
    "  <li>Implement the objective function <code>f(z) = ∥w∥²</code>.</li>\n",
    "  <li>Solve the optimization problem using CVXPY to check if the dataset is linearly separable.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwkY6AlDnjSK",
    "outputId": "6ada7fc4-f2b2-40d3-e4cb-fd2860af3a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvxpy in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
      "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (0.6.7.post0)\n",
      "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (2.0.14)\n",
      "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (0.9.0)\n",
      "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (3.2.7)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cvxpy) (1.13.1)\n",
      "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->cvxpy) (0.1.7.post4)\n"
     ]
    }
   ],
   "source": [
    "!pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcCbsAIgnjSO",
    "outputId": "4e1f0393-fc49-440f-afc5-b8e57c0789cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is linearly separable!\n",
      "Optimal weight vector (w): [3.84732296e-12 2.17605319e-11]\n",
      "Optimal bias (b): -2.053907262666263e-11\n",
      "Optimal margin (gamma): -2.6365280554751554e-11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "# Sample dataset D = {(x_i, y_i)}: n data points with d features\n",
    "# Example dataset for illustration (you can replace with your actual data)\n",
    "n = 5  # Number of data points\n",
    "d = 2  # Dimensionality of each data point\n",
    "\n",
    "# Example dataset (x_i, y_i)\n",
    "X = np.array([[1, 2], [2, 3], [3, 3], [4, 5], [1, 1]])  # Each row is a data point x_i\n",
    "y = np.array([1, 1, -1, -1, 1])  # Corresponding labels y_i\n",
    "\n",
    "# Decision variables\n",
    "w = cp.Variable(d)       # Weight vector of size d\n",
    "b = cp.Variable()        # Bias term\n",
    "gamma = cp.Variable()    # Margin term\n",
    "\n",
    "# Define the constraints: y_i * (⟨w, x_i⟩ - b) >= gamma\n",
    "constraints = [y[i] * (X[i, :] @ w - b) >= gamma for i in range(n)]\n",
    "constraints.append(gamma >= 0)  # Ensure gamma is positive\n",
    "\n",
    "# Objective function: minimize ||w||^2 (for feasibility checking, we don't optimize anything specific)\n",
    "objective = cp.Minimize(cp.norm(w, 2))\n",
    "\n",
    "# Formulate the optimization problem\n",
    "problem = cp.Problem(objective, constraints)\n",
    "\n",
    "# Solve the problem\n",
    "result = problem.solve()\n",
    "\n",
    "# Output the results\n",
    "if problem.status == cp.OPTIMAL:\n",
    "    print(f\"The dataset is linearly separable!\")\n",
    "    print(f\"Optimal weight vector (w): {w.value}\")\n",
    "    print(f\"Optimal bias (b): {b.value}\")\n",
    "    print(f\"Optimal margin (gamma): {gamma.value}\")\n",
    "else:\n",
    "    print(f\"The dataset is not linearly separable.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XlOybginjSP"
   },
   "source": [
    "<h3>Explanation:</h3>\n",
    "\n",
    "<h4>Decision Variables:</h4>\n",
    "<p>\n",
    "We define <code>w</code> (weight vector) as a <code>cvxpy.Variable</code> of size <code>d</code>, representing the dimension of each data point.<br>\n",
    "We define <code>b</code> (bias) and <code>γ</code> (margin) as scalar decision variables.\n",
    "</p>\n",
    "\n",
    "<h4>Constraints:</h4>\n",
    "<p>\n",
    "We construct the constraint <code>y<sub>i</sub>(⟨w, x<sub>i</sub>⟩ − b) ≥ γ</code> for each data point <code>i</code>.<br>\n",
    "We also add the constraint <code>γ > 0</code> to ensure the margin is positive.\n",
    "</p>\n",
    "\n",
    "<h4>Objective Function:</h4>\n",
    "<p>\n",
    "We minimize <code>∥w∥<sup>2</sup></code>, the Euclidean norm of the weight vector, as a regularization to ensure we are not trivializing the solution.\n",
    "</p>\n",
    "\n",
    "<h4>Solver:</h4>\n",
    "<p>\n",
    "The optimization problem is solved using the <code>cvxpy.Problem()</code> class and its <code>solve()</code> method.<br>\n",
    "We check the <code>problem.status</code> to see if the problem is <code>OPTIMAL</code>, which would indicate that a linear separator exists, meaning the dataset is linearly separable.\n",
    "</p>\n",
    "\n",
    "<h4>Observations:</h4>\n",
    "<ul>\n",
    "  <li>If the solver returns an optimal solution, the dataset is linearly separable, and the values of <code>w</code>, <code>b</code>, and <code>γ</code> will represent the separating hyperplane and margin.</li>\n",
    "  <li>If the solver cannot find an optimal solution (e.g., <code>problem.status != cp.OPTIMAL</code>), it means the dataset is not linearly separable.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjR7b0gnnjSP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5V-tQsBSnjSQ"
   },
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvR5P0xUHt4z",
    "outputId": "f1ca1142-d0a5-40c6-f096-ad6091682b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Linearly separable\n",
      "Dataset 2: Linearly separable\n",
      "Dataset 3: Not linearly separable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "# Function to check linear separability using CVXPY\n",
    "def check_linear_separability(data):\n",
    "    # Separate features (first four columns) and labels (last column)\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    # Modify labels to be +1 and -1 if they are not already\n",
    "    y = np.where(y == 1, 1, -1)\n",
    "\n",
    "    # Number of samples and features\n",
    "    n, d = X.shape\n",
    "\n",
    "    # Decision variables\n",
    "    w = cp.Variable(d)\n",
    "    b = cp.Variable()\n",
    "    gamma = cp.Variable()\n",
    "\n",
    "    # Define a small epsilon to avoid strict inequality\n",
    "    epsilon = 1e-5\n",
    "\n",
    "    # Define constraints: y_i * (w @ x_i - b) >= gamma for each sample i\n",
    "    constraints = [y[i] * (X[i, :] @ w - b) >= gamma for i in range(n)]\n",
    "    constraints.append(gamma >= epsilon)\n",
    "\n",
    "    # Objective: minimize ||w||^2 (for feasibility checking)\n",
    "    objective = cp.Minimize(cp.norm(w, 2))\n",
    "\n",
    "    # Formulate and solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    result = problem.solve()\n",
    "\n",
    "    # Check if the problem is solved optimally\n",
    "    if problem.status == cp.OPTIMAL:\n",
    "        return \"Linearly separable\"\n",
    "    else:\n",
    "        return \"Not linearly separable\"\n",
    "\n",
    "# Load the datasets\n",
    "data1 = pd.read_csv('data1.csv', names=['a1', 'b1', 'c1', 'd1', 'label'])\n",
    "data2 = pd.read_csv('data2.csv', names=['a2', 'b2', 'c2', 'd2', 'label'])\n",
    "data3 = pd.read_csv('data3.csv', names=['a3', 'b3', 'c3', 'd3', 'label'])\n",
    "\n",
    "# Check linear separability for all three datasets\n",
    "result1 = check_linear_separability(data1)\n",
    "result2 = check_linear_separability(data2)\n",
    "result3 = check_linear_separability(data3)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Dataset 1: {result1}\")\n",
    "print(f\"Dataset 2: {result2}\")\n",
    "print(f\"Dataset 3: {result3}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "657EgXC_suxU"
   },
   "source": [
    "# D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking linear seprability by Perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1.csv is linearly separable.\n",
      "data2.csv is linearly separable.\n",
      "data3.csv is not linearly separable.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, max_iter=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                y_predicted = np.sign(linear_output)\n",
    "\n",
    "                if y_predicted != y[idx]:\n",
    "                    self.weights += self.learning_rate * (y[idx] - y_predicted) * x_i\n",
    "                    self.bias += self.learning_rate * (y[idx] - y_predicted)\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.sign(linear_output)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data(file_path):\n",
    "        data = pd.read_csv(file_path, header=None)\n",
    "        X = data.iloc[:, :-1].values  # All columns except last as features\n",
    "        y = data.iloc[:, -1].values    # Last column as target\n",
    "        return X, y\n",
    "\n",
    "# List of dataset file paths\n",
    "datasets = ['data1.csv', 'data2.csv', 'data3.csv']\n",
    "\n",
    "# Iterate through each dataset\n",
    "for dataset in datasets:\n",
    "    X, y = Perceptron.load_data(dataset)\n",
    "    y = np.where(y == 1, 1, -1)  # Convert target variable to -1 and 1\n",
    "\n",
    "    # Initialize and fit the perceptron\n",
    "    percep = Perceptron()\n",
    "    percep.fit(X, y)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = percep.predict(X)\n",
    "\n",
    "    # Check if linearly separable\n",
    "    if np.array_equal(predictions, y):\n",
    "        print(f\"{dataset} is linearly separable.\")\n",
    "    else:\n",
    "        print(f\"{dataset} is not linearly separable.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcW5ortCts3W"
   },
   "source": [
    "## Explanation:\n",
    "\n",
    "### Perceptron Class:\n",
    "The Perceptron class initializes the weights and bias. For each iteration, it checks if any data points are misclassified (i.e., violate the condition \n",
    "\\(y_i (w \\cdot x_i + b) > 0\\)). If a misclassification is found, it updates the weights and bias according to the Perceptron update rule. If the algorithm completes without finding any misclassified points, the dataset is linearly separable.\n",
    "\n",
    "### Checking Linear Separability:\n",
    "We load the dataset, split it into features (X) and labels (y), and then run the perceptron algorithm on it. If the perceptron converges (i.e., finds a solution without misclassifications), the dataset is considered linearly separable. If the algorithm runs for the maximum number of iterations without converging, the dataset is not linearly separable.\n",
    "\n",
    "### Justification of Approach:\n",
    "The perceptron algorithm is guaranteed to converge in a finite number of iterations if and only if the dataset is linearly separable. If the algorithm fails to converge, it implies that no linear separator exists. In this implementation, convergence within the maximum number of iterations indicates that the dataset is linearly separable. This approach is both correct and justified because the perceptron algorithm is a standard tool for testing linear separability of datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
